---
layout: post
title: 关于数据科学不易触及的真相
category: 学习观点
tags: [个人观点]
description: 关于数据科学不易触及的真相
---

关于数据科学不易触及的真相，英文原文参考: [The Inconvenient Truth About Data Science](https://www.linkedin.com/pulse/inconvenient-truth-data-science-kamil-bartocha)。本文针对这些真相，结合自己的一些实践经历做了一些个人解读。我个人是搞过数据分析（甲方乙方都呆过），写过一些报告，也负责一些工程上的实现和建模，包括深度学习。但经验和专业能力有限，所以很多都是自己的一时之见，可以批判的看看。

<!-- more -->

###目录
{:.no_toc}

* 目录
{:toc}

### 关于数据
**Data is never clean.** 
数据永远是不干净的。换句话说，数据都是需要清洗的。这里补充一点：永远不要相信别人给你的数据就是正确的，每次都要检查数据的来源以及看看数据是什么样子。以前在某家公司工作中，数据部不能直接连接数据库，需要运营给数据，检查的时候发现他给的数据有各种错误，根本不是你想要的数据需求。对于很多其他部门提供的一些excel，都没有标准，导致各种数据混乱。这一点，在数据清洗里，在具体说一下。


###关于数据清洗
**You will spend most of your time cleaning and preparing data.**
很多数据，都是堆放在数据仓库中，或者一堆文本、excel文件里，我们需要根据自己的分析目标去取所需要的数据。关于数据清洗，主要是看看是否有缺失，是否有重复或者错误等等。其实，在数据操作中，每一步都是有意义的，而这些都取决于你的分析目的。你要做什么样的分析，就对应了你需要什么样的数据，就需要你做什么样的清洗，没必要花时间清洗那些不相关的数据。另外，很多清洗都是在数据探索中发现的，比如在数据探索中，发现一些地理位置是不规范的，需要清洗和规范等等。

此外，我们绝大多数的分析工具对数据输入都是有要求的，所以需要各种整理数据。这里提一个关键的东西——“数据字典”。这个在之前的工作中用到，简单的说数据字典概述了不同数据的属性说明，存储以及字段，有些数据词语涉及完整的数据定义等等。另外，有些存储是基于数据字典的。比如存储“非政府非盈利性组织”，可以用“org”来表示，这一方面是优化了存储，另一方面在分析的时候也会很方便，毕竟很多分析系统对中文的支持不是很好，避免各种编码问题。但是，这里必须要提及一点，就是不能为了构建字典而构建字典，有些业务是不必要的。而我个人比较支持的数据字典，是一种以业务场景划分，各个数据属性和说明的一个文档，也可以是思维导图。这样，可以很方便查看目前有哪些数据，我们主要的业务场景，以及有利于分析框架的制定。此外，新员工入职也可以很方便的。

###关于技术
**95% of tasks do not require deep learning.**
大多数任务都不需要深度学习。目前深度学习是比较火爆，但是没有很好的数据支持和硬件支持，还是不建议搞深度学习。深度学习模型的参数很多，很依赖数据，另外训练比较慢，没有GPU的支持，训练会非常的慢。此外，我们使用了开源的一些框架训练一些模型，如何部署这些模型也是很大的问题。最后，深度学习的核心是特征学习，你搞不定特征的时候才会考虑，而且目前也只是在一些特定的场景中得到应用。在具体的业务场景中，尤其是特征比较固定的情况下，比如行为分析里一些统计特征，年龄，地区等等，这些用深度学习做特征处理反而不利于模型的解释，而且未必能得到好的结果。

###关于回归
**In 90% of cases generalized linear regression will do the trick.**
这个没啥说的，trick是哪哪都需要的东西。深度学习里的trick也是很多很多。核方法也是被称之为trick的方法，所以我觉得这里主要是想表达需要做很多特征工程。比如以前搞同事搞一个模型，说效果不好。看了看，发现数据中“收入”是有偏的，不利于整合模型，做了对数处理，均衡一下分布，模型效果就好了很多。当然，很多trick，有时候也说不好为什么有用，但是有些却很有道理样子。这个也算是调参的一部分吧。

###关于大数据
**Big Data is just a tool.** 
大数据只是一个工具。对于分析师而言，确实是这样。你不需要懂太多技术原理，能够很好的使用就可以了。比如Hive，你不需要知道他怎么存储的，也不需要知道出问题怎么办，你只要会HQL，能够很合理的提取数据就可以了。当然，这是建立在分析的基础上。如果是建模的话，那么你对自己的建模工具的理解，也是很重要的。如果是对于工程师而言，那么你需要的不仅仅是使用了，而是开发能力了。
目前看来很多企业需求，是需要那种懂模型的同时，又有很好的工程实现能力。这方面，统计系的很难跟计算机系的比了。而且，认识很多非常懂机器学习原理，也能自己写代码实现工程的人。所以，这是两个职业方向，一个是分析师，一个是工程师。自己需要选择适合自己的道路，去优化自己的技能，提升自己的能力。我个人是比较偏向于工程师，但是分析是基础，也是一辈子都值得好好学习和拥有的技能。

###拥抱贝叶斯
**You should embrace the Bayesian approach.**
这个正对我的思路。我个人也比较倾向于贝叶斯学派，机器学习从NG的课程开始，翻译他的课件，整体上是偏频率学派的。后来，觉得贝叶斯更适合自己的思维，目前也是在努力的啃PRML。简单的解释下，就是最大似然是含着“过拟合”出生的，字面理解一下最大似然，就是使得已经发生的事情发生的似然概率最大。这样会导致小数据下，一些小概率事件被放大为大概率事件。当然，很多书籍都有介绍。贝叶斯推断以及决策理论等等书籍，都是很值得推荐的。

###关于细节
**No one cares how you did it.**
数据分析和工程实现，都是非常注重细节的。很多细节的错误，导致最后分析完全错误，或者工程bug不断。一些小细节，也会导致你白白忙了一整天。但是，别人是不关注的。别人更多的关注是你做了什么，这个结果是不是合理以及评估你结论的可行性等等。比如之前搞过一个项目，中间用来一些trick，就是随机了一些数据进去，使得结果比较符合常识上，这个从道理上来说，你是不能随便更改数据的（但是，这里不是做分析报告和评估，是工程项目，所以可以用一些trick，就像百度搜索做了很多人工优化一样）。但是，项目演示的时候，大家都觉得很好，因为做出来的结果比较符合常识，没有明显的不合理地方。 


###关于学术和企业
**Academia and business are two different worlds.**
这个感受也比较深。在学术方面，你可以用一些trick，或者更加复杂的模型来提高模型的精度和鲁棒性，但是在工程里，这些是不容易维护的，尤其是时间方面。学术里，你可以用3s跑一个模型，但是工程要求你必须0.5s内跑完模型。

###关于PPT
**Presentation is key - be a master of Power Point.**
这个分很多场景，比如给客户讲还是给同事讲，还是给领导讲等等。在给客户讲的时候，我感觉可能忽悠多一点。PPT要做好，不一定非要高达上的动画什么，但是有一个好的模板很重要！另外，感受比较深的是，你一定要把握你的听众。这方面，我经验也比较少，更多的是做了同事之间的分享，给领导汇报的少。

###关于对错
**All models are false, but some are useful.**
这个不用说，统计学界经典名言。工业界更是如此，在实际中很难满足模型的各种基础假设，比如高斯分布，独立性等等。虽然各种假设检验，我基本没怎么用过。但是，皮尔逊-奈曼范式，我还是很欣赏的。

###关于自动化
**There is no fully automated Data Science. You need to get your hands dirty.** 
最开始工作的时候，我也想着自动化分析，出报告等等。做的多了，发现这个不太科学。因为业务的发展，数据的变化层出不穷，各种之前没有遇到的情况会出现。但是，自动化报表还是可以有的。我们可以根据自动化报表得到的结果，进行进一步的分析。这样的做法，是在数据准备阶段，做了一些比较完善的处理。但是，如果自己不去探索数据，而直接考报表的一堆图表来分析的话，可能会错过很多细节上的信息。很多分析，就会变得流程化，机械化。我个人是比较反对机械化分析的，但凡机械化分析都应该由机器去做，人应该更多的是做具有创造性的工作！

